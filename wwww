import pandas as pd
import numpy as np
import math
import re
import asyncio
import os
import time
import random
from datetime import datetime, timedelta
from urllib.parse import urlparse
from playwright.async_api import async_playwright
from concurrent.futures import ProcessPoolExecutor

# =========================================================
# 1. C·∫§U H√åNH SI√äU T·ªêC
# =========================================================
INPUT_FILE = "Dataset_Ready_to_Train.csv"
OUTPUT_FILE = "Dataset_18_Features_Final.csv"
LOG_FILE = "detailed_process.log"
TOP_1M_FILE = "top-1m.csv"

NUM_PROCESSES = 3         # S·ªë c·ª≠a s·ªï tr√¨nh duy·ªát ch·∫°y song song (Kali 8GB RAM n√™n ƒë·ªÉ 3-4)
PAGES_PER_PROCESS = 3     # M·ªói c·ª≠a s·ªï m·ªü bao nhi√™u tab
TIMEOUT = 70000           

# =========================================================
# 2. H√ÄM TR√çCH XU·∫§T CH√çNH (X·ª≠ l√Ω trong 1 Process)
# =========================================================

async def apply_stealth(page):
    await page.add_init_script("""
        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
        window.chrome = { runtime: {} };
    """)

async def process_url(url, label, context, semaphore, log_file):
    static_data = extract_static(url) # H√†m static gi·ªØ nguy√™n nh∆∞ c≈©
    dynamic_data = {f: 0.5 for f in ['Outlink_Ratio', 'HasExternalFormSubmit', 'HasPasswordField', 'DomainTitleMatchScore', 
                                    'HasSocialNet', 'HasCopyrightInfo', 'HasDescription', 'V9_Has_Hidden_IFrame']}
    
    status = "FAILED"
    check_info = ""

    async with semaphore:
        page = await context.new_page()
        await apply_stealth(page)
        try:
            await page.goto(url, timeout=TIMEOUT, wait_until="networkidle")
            
            # Gi·∫£ l·∫≠p h√†nh vi
            await page.mouse.wheel(0, 500)
            await asyncio.sleep(random.uniform(4, 6))

            title = (await page.title()) or "No Title"
            domain = urlparse(url).netloc
            content = (await page.content()).lower()

            # Tr√≠ch xu·∫•t IFrame ·∫©n (V9)
            v9 = 1 if any(not await f.frame_element().is_visible() for f in page.frames[1:] if f.frame_element()) else 0
            
            # Outlink Ratio
            links = await page.query_selector_all('a')
            ext_l = 0
            for l in links:
                h = await l.get_attribute('href')
                if h and 'http' in h and domain not in h: ext_l += 1
            
            outlink_ratio = ext_l / len(links) if links else 0

            dynamic_data.update({
                'Outlink_Ratio': outlink_ratio,
                'V9_Has_Hidden_IFrame': v9,
                'DomainTitleMatchScore': 1 if domain.split('.')[0].lower() in title.lower() else 0,
                'HasPasswordField': 1 if await page.query_selector('input[type="password"]') else 0,
            })
            status = "SUCCESS"
            check_info = f"Title: {title[:30]}... | Outlink: {outlink_ratio:.2f} | V9: {v9}"
        except Exception as e:
            check_info = str(e)[:30]
        finally:
            await page.close()
            
    # Ghi log chi ti·∫øt ƒë·ªÉ check
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now().strftime('%H:%M:%S')}] {status} | {url} | {check_info}\n")
    
    return {**static_data, **dynamic_data, 'url': url, 'label': label}

# =========================================================
# 3. QU·∫¢N L√ù ƒêA LU·ªíNG (ASYNCHRONOUS RUNNER)
# =========================================================

async def run_batch(df_batch, process_id):
    results = []
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False, args=['--disable-blink-features=AutomationControlled'])
        context = await browser.new_context(viewport={'width': 1280, 'height': 800})
        semaphore = asyncio.Semaphore(PAGES_PER_PROCESS)
        
        tasks = [process_url(row['url'], row['label'], context, semaphore, LOG_FILE) for _, row in df_batch.iterrows()]
        results = await asyncio.gather(*tasks)
        
        await browser.close()
    return results

def process_entry(df_batch, process_id):
    return asyncio.run(run_batch(df_batch, process_id))

# =========================================================
# 4. H√ÄM STATIC & MAIN (D·ª∞ ƒêO√ÅN TH·ªúI GIAN)
# =========================================================

def extract_static(url):
    # (Gi·ªØ nguy√™n h√†m extract_static c≈© c·ªßa √¥ng ·ªü ƒë√¢y)
    return {'domainLength': len(url)} # V√≠ d·ª• r√∫t g·ªçn

if __name__ == "__main__":
    start_time = time.time()
    df_all = pd.read_csv(INPUT_FILE)
    
    # Check log ƒë·ªÉ resume (kh√¥ng c√†o l·∫°i)
    processed_urls = set()
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            for line in f:
                parts = line.split(" | ")
                if len(parts) > 1: processed_urls.add(parts[1].strip())

    df_todo = df_all[~df_all['url'].isin(processed_urls)]
    total = len(df_todo)
    print(f"üöÄ B·∫Øt ƒë·∫ßu c√†o {total} URL v·ªõi {NUM_PROCESSES} lu·ªìng...")

    batch_size = 20 # L∆∞u file sau m·ªói 20 URL
    for i in range(0, total, batch_size):
        current_batch = df_todo.iloc[i : i + batch_size]
        
        # Chia nh·ªè batch cho c√°c Process
        sub_batches = np.array_split(current_batch, NUM_PROCESSES)
        
        with ProcessPoolExecutor(max_workers=NUM_PROCESSES) as executor:
            futures = [executor.submit(process_entry, sub_batches[p], p) for p in range(NUM_PROCESSES)]
            batch_results = []
            for fut in futures:
                batch_results.extend(fut.result())
        
        # L∆∞u d·ªØ li·ªáu ngay l·∫≠p t·ª©c
        df_res = pd.DataFrame(batch_results)
        df_res.to_csv(OUTPUT_FILE, mode='a', index=False, header=not os.path.exists(OUTPUT_FILE))
        
        # D·ª± ƒëo√°n th·ªùi gian (ETA)
        done = i + len(current_batch)
        elapsed = time.time() - start_time
        speed = done / elapsed
        eta = str(timedelta(seconds=int((total - done) / speed)))
        print(f"‚úÖ ƒê√£ xong {done}/{total} | T·ªëc ƒë·ªô: {speed:.2f} URL/s | ETA: {eta}")
