import pandas as pd
import numpy as np
import math
import re
import asyncio
import os
import requests
import io
import csv
import time
import gc
from urllib.parse import urlparse
from playwright.async_api import async_playwright
from concurrent.futures import ProcessPoolExecutor

# ================= Cáº¤U HÃŒNH Tá»I Æ¯U (27GB RAM) =================
URLHAUS_URL = "https://urlhaus.abuse.ch/downloads/csv_online/"
OUTPUT_FILE = "Phishing_Web_24F_Final.csv"
LIMIT_URLS = 15000          

NUM_PROCESSES = 10           # Sá»‘ nhÃ¢n CPU xá»­ lÃ½ (tÄƒng/giáº£m tÃ¹y CPU)
CONCURRENT_PER_PROC = 5      # Sá»‘ tab má»Ÿ cÃ¹ng lÃºc trong má»—i nhÃ¢n
RESTART_BROWSER_EVERY = 100  # Cá»±c ká»³ quan trá»ng Ä‘á»ƒ giáº£i phÃ³ng RAM
TIMEOUT_MS = 30000           # 30 giÃ¢y cho má»—i trang

# Danh sÃ¡ch Ä‘uÃ´i file khÃ´ng pháº£i web (trÃ¡nh táº£i file Ä‘á»™c háº¡i vá» mÃ¡y)
FILE_BLACKLIST = ('.exe', '.bin', '.dll', '.msi', '.apk', '.zip', '.rar', '.7z', '.tmp', 
                  '.lin', '.sh', '.bat', '.iso', '.dmg', '.gz', '.i', '.dat', '.pdf', '.txt')

# ================= CÃC HÃ€M Bá»” TRá»¢ =================
def calculate_entropy(text):
    if not text or len(text) == 0: return 0
    prob = [float(text.count(c)) / len(text) for c in dict.fromkeys(list(text))]
    return -sum(p * math.log(p, 2) for p in prob)

async def get_features(context, url):
    """HÃ m trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vá»›i cÆ¡ cháº¿ chá»‘ng cháº·n nÃ¢ng cao"""
    page = await context.new_page()
    data = None
    try:
        # 1. VÆ¯á»¢T CHáº¶N: Giáº£ láº­p vÃ¢n tay trÃ¬nh duyá»‡t tháº­t
        await page.set_extra_http_headers({
            "Accept-Language": "en-US,en;q=0.9",
            "Referer": "https://www.google.com/"
        })

        # 2. TÄ‚NG Tá»C: Cháº·n táº£i cÃ¡c tÃ i nguyÃªn tá»‘n RAM/BÄƒng thÃ´ng
        await page.route("**/*", lambda route: 
            route.abort() if route.request.resource_type in ["image", "media", "font", "stylesheet"] 
            else route.continue_()
        )

        # 3. TRUY Cáº¬P: DÃ¹ng domcontentloaded Ä‘á»ƒ láº¥y dá»¯ liá»‡u nhanh nháº¥t
        response = await page.goto(url, timeout=TIMEOUT_MS, wait_until="domcontentloaded")
        
        # Kiá»ƒm tra náº¿u khÃ´ng pháº£i HTML (vÃ­ dá»¥ link táº£i file áº©n) thÃ¬ bá» qua
        ctype = response.headers.get('content-type', '').lower()
        if 'text/html' not in ctype:
            await page.close()
            return None

        # 4. GIáº¢ Láº¬P NGÆ¯á»œI DÃ™NG: Cuá»™n nháº¹ trang Ä‘á»ƒ kÃ­ch hoáº¡t JS/Iframe ngáº§m
        await page.mouse.wheel(0, 500)
        await asyncio.sleep(2) # Äá»£i JS render

        content = (await page.content()).lower()
        title = (await page.title()) or ""
        domain = urlparse(url).netloc.lower()
        visible_text = await page.evaluate("() => document.body.innerText")
        
        digits = sum(c.isdigit() for c in url)
        is_https = 1 if url.startswith('https') else 0

        # TrÃ­ch xuáº¥t 24 Ä‘áº·c trÆ°ng (Features)
        data = {
            'URL': url,
            'NoOfDegitsInURL': digits,
            'IsHTTPS': is_https,
            'DomainTitleMatchScore': 1 if domain.split('.')[0] in title.lower() and len(title) > 0 else 0,
            'HasDescription': 1 if await page.query_selector('meta[name="description"]') else 0,
            'HasExternalFormSubmit': 1 if await page.query_selector('form[action^="http"]') else 0,
            'HasSocialNet': 1 if any(s in content for s in ['facebook.com', 'twitter.com', 'instagram.com']) else 0,
            'HasSubmitButton': 1 if await page.query_selector('input[type="submit"], button[type="submit"], button') else 0,
            'HasPasswordField': 1 if await page.query_selector('input[type="password"]') else 0,
            'HasCopyrightInfo': 1 if 'Â©' in content or 'copyright' in content else 0,
            'label': 1,
            'V1_PHash_Distance': 0, 
            'V2_Layout_Similarity': 0,
            'V6_JS_Entropy': calculate_entropy(content),
            'V7_Text_Readability_Score': len(visible_text.split()) / 400 if visible_text else 0,
            'V8_Total_IFrames': len(await page.query_selector_all('iframe')),
            'V9_Has_Hidden_IFrame': 1 if await page.query_selector('iframe[style*="display:none"]') else 0,
            'V5_TLS_Issuer_Reputation': is_https,
            'V4_DNS_Volatility_Count': 0, 
            'Is_Top_1M_Domain': 0,
            'V22_IP_Subdomain_Pattern': 1 if re.match(r'\d+\.\d+\.\d+', domain) else 0,
            'V23_Entropy_Subdomain': calculate_entropy(domain.split('.')[0]),
            'Trust_Score': is_https,
            'Digit_Ratio': digits / len(url) if len(url) > 0 else 0
        }
    except Exception:
        pass # Bá» qua cÃ¡c link cháº¿t (timeout, nxdomain, v.v.)
    finally:
        await page.close() # Giáº£i phÃ³ng RAM cá»§a tab ngay láº­p tá»©c
        return data

async def worker(urls, proc_id):
    """Quáº£n lÃ½ vÃ²ng Ä‘á»i trÃ¬nh duyá»‡t vÃ  giáº£i phÃ³ng bá»™ nhá»› há»‡ thá»‘ng"""
    # Chia nhá» danh sÃ¡ch URL Ä‘á»ƒ khá»Ÿi Ä‘á»™ng láº¡i browser Ä‘á»‹nh ká»³
    url_chunks = [urls[i:i + RESTART_BROWSER_EVERY] for i in range(0, len(urls), RESTART_BROWSER_EVERY)]
    
    for chunk in url_chunks:
        async with async_playwright() as p:
            # Khá»Ÿi Ä‘á»™ng trÃ¬nh duyá»‡t vá»›i cÃ¡c cá» (flags) áº©n bot
            browser = await p.chromium.launch(headless=True, args=[
                '--no-sandbox', 
                '--disable-dev-shm-usage', # TrÃ¡nh trÃ n bá»™ nhá»› Ä‘á»‡m Linux/Docker
                '--disable-blink-features=AutomationControlled' # VÆ°á»£t cháº·n Navigator.webdriver
            ])
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )

            results = []
            for i in range(0, len(chunk), CONCURRENT_PER_PROC):
                batch = chunk[i : i + CONCURRENT_PER_PROC]
                tasks = [get_features(context, url) for url in batch]
                
                # Cháº¡y song song nhiá»u tab (concurrency)
                batch_results = await asyncio.gather(*tasks)
                
                for res in batch_results:
                    if res: results.append(res)

                # LÆ°u vÃ o file CSV sau má»—i batch thÃ nh cÃ´ng
                if results:
                    df = pd.DataFrame(results)
                    df.to_csv(OUTPUT_FILE, mode='a', header=not os.path.exists(OUTPUT_FILE), index=False)
                    results = []

                print(f"âœ”ï¸ [P{proc_id}] Xá»­ lÃ½: {i + len(batch)}/{len(chunk)}")

            await browser.close()
        
        # Buá»™c Python giáº£i phÃ³ng rÃ¡c trong RAM sau khi Ä‘Ã³ng Browser
        gc.collect()
        print(f"ğŸ§¹ [P{proc_id}] ÄÃ£ khá»Ÿi Ä‘á»™ng láº¡i trÃ¬nh duyá»‡t Ä‘á»ƒ lÃ m sáº¡ch RAM.")

def start_process(urls, proc_id):
    """Äiá»ƒm kÃ­ch hoáº¡t cho Ä‘a tiáº¿n trÃ¬nh"""
    asyncio.run(worker(urls, proc_id))

# ================= CHÆ¯Æ NG TRÃŒNH CHÃNH =================
if __name__ == "__main__":
    # 1. Äá»ŒC CHECKPOINT: KhÃ´ng cÃ o láº¡i nhá»¯ng URL Ä‘Ã£ cÃ³
    processed_urls = set()
    if os.path.exists(OUTPUT_FILE):
        try:
            old_df = pd.read_csv(OUTPUT_FILE, usecols=['URL'])
            processed_urls = set(old_df['URL'].astype(str).tolist())
            print(f"ğŸ”„ ÄÃ£ tÃ¬m tháº¥y {len(processed_urls)} máº«u cÅ©. Äang lá»c URL má»›i...")
        except: pass

    # 2. Táº¢I Dá»® LIá»†U: Láº¥y danh sÃ¡ch URL Ä‘á»™c háº¡i má»›i nháº¥t
    print("ğŸ“¥ Äang táº£i URLHaus Online List...")
    try:
        res = requests.get(URLHAUS_URL, timeout=30)
        reader = csv.reader(io.StringIO(res.text))
        phish_urls = []
        for row in reader:
            if len(row) > 3 and row[3] == 'online':
                url = row[2]
                # Kiá»ƒm tra blacklist file vÃ  trÃ¹ng láº·p
                if not url.lower().endswith(FILE_BLACKLIST) and url not in processed_urls:
                    phish_urls.append(url)
            if len(phish_urls) >= LIMIT_URLS: break
    except Exception as e:
        print(f"âŒ Lá»—i táº£i dá»¯ liá»‡u: {e}")
        exit()

    # 3. THá»°C THI: Chia viá»‡c cho cÃ¡c nhÃ¢n CPU
    total = len(phish_urls)
    if total > 0:
        print(f"ğŸš€ Báº¯t Ä‘áº§u quÃ©t {total} URL vá»›i 10 Process x 5 Tab...")
        chunks = np.array_split(phish_urls, NUM_PROCESSES)
        with ProcessPoolExecutor(max_workers=NUM_PROCESSES) as executor:
            for i in range(NUM_PROCESSES):
                executor.submit(start_process, chunks[i].tolist(), i)
    else:
        print("ğŸ‰ KhÃ´ng cÃ³ URL má»›i nÃ o cáº§n xá»­ lÃ½!")

    print(f"ğŸ Táº¤T Cáº¢ ÄÃƒ XONG! File lÆ°u táº¡i: {OUTPUT_FILE}")
