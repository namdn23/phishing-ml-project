import pandas as pd
import numpy as np
import math
import re
import asyncio
import os
import time
import random
from datetime import datetime, timedelta
from urllib.parse import urlparse
from playwright.async_api import async_playwright

# =========================================================
# 1. Cáº¤U HÃŒNH Há»† THá»NG
# =========================================================
INPUT_FILE = "Dataset_Ready_to_Train.csv"
OUTPUT_FILE = "Dataset_18_Features_Final.csv"
LOG_FILE = "processed_urls.log"
TOP_1M_FILE = "top-1m.csv"

# CHá»ˆ Sá» VÃ€NG: Giáº£m luá»“ng Ä‘á»ƒ táº­p trung vÆ°á»£t cháº·n tá»«ng trang
CONCURRENT_PAGES = 5  
TIMEOUT = 90000       # 90 giÃ¢y Ä‘á»ƒ Ä‘á»§ thá»i gian giáº£i mÃ£ Cloudflare
MAX_RETRIES = 2

# =========================================================
# 2. ULTRA STEALTH V3: GIáº¢ Láº¬P THIáº¾T Bá»Š DI Äá»˜NG
# =========================================================
async def apply_stealth_v3(page):
    await page.add_init_script("""
        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
        Object.defineProperty(navigator, 'deviceMemory', {get: () => 8});
        window.chrome = { runtime: {} };
        // Giáº£ láº­p cáº£m á»©ng (Touch) Ä‘á»ƒ giá»‘ng Ä‘iá»‡n thoáº¡i
        Object.defineProperty(navigator, 'maxTouchPoints', {get: () => 5});
    """)

# =========================================================
# 3. TRÃCH XUáº¤T STATIC (Giá»¯ nguyÃªn logic cá»§a Ã´ng)
# =========================================================
try:
    top_1m_set = set(pd.read_csv(TOP_1M_FILE, header=None)[1].astype(str).str.lower().values)
except:
    top_1m_set = set()

def calculate_entropy(text):
    if not text: return 0
    p_x = [float(text.count(chr(x))) / len(text) for x in range(256) if text.count(chr(x)) > 0]
    return -sum(p * math.log(p, 2) for p in p_x)

def extract_static(url):
    parsed = urlparse(url)
    domain = parsed.netloc.lower()
    return {
        'domainEntropy': calculate_entropy(domain),
        'V23_Entropy_Subdomain': calculate_entropy(domain.split('.')[0]),
        'hasIp': 1 if re.match(r'\d+\.\d+\.\d+\.\d+', domain) else 0,
        'numHypRatio': domain.count('-') / len(domain) if len(domain) > 0 else 0,
        'domainLength': len(domain),
        'Subdomain_Level': domain.count('.'),
        'IsHTTPS': 1 if url.startswith('https') else 0,
        'Is_Top_1M_Domain': 1 if any(d in top_1m_set for d in [domain, '.'.join(domain.split('.')[-2:])]) else 0
    }

# =========================================================
# 4. TRÃCH XUáº¤T Äá»˜NG: CHIáº¾N THUáº¬T VÆ¯á»¢T CHáº¶N Tá»”NG Lá»°C
# =========================================================
async def extract_task(url, label, context, semaphore, log_handle):
    static_data = extract_static(url)
    status = "FAILED"
    dynamic_data = {f: 0.5 for f in ['Outlink_Ratio', 'HasExternalFormSubmit', 'HasPasswordField', 'DomainTitleMatchScore', 
                                    'HasSocialNet', 'HasCopyrightInfo', 'HasDescription', 'V9_Has_Hidden_IFrame', 
                                    'V5_TLS_Issuer_Reputation', 'V4_DNS_Volatility_Count']}

    if static_data['Is_Top_1M_Domain'] == 1:
        status = "SKIP"
        dynamic_data = {k: 1.0 if k not in ['Outlink_Ratio', 'V9_Has_Hidden_IFrame'] else 0.0 for k in dynamic_data.keys()}
    else:
        async with semaphore:
            for attempt in range(MAX_RETRIES):
                page = await context.new_page()
                await apply_stealth_v3(page)
                
                try:
                    # DÃ¹ng Referer tá»« máº¡ng xÃ£ há»™i (vÆ°á»£t cháº·n tá»‘t hÆ¡n Google)
                    await page.set_extra_http_headers({"Referer": "https://t.co/"})
                    
                    # BÆ°á»›c 1: Truy cáº­p vá»›i thá»i gian chá» dÃ i
                    await page.goto(url, timeout=TIMEOUT, wait_until="networkidle")
                    
                    # BÆ°á»›c 2: TÆ°Æ¡ng tÃ¡c ngÆ°á»i tháº­t Ä‘á»ƒ "nhá»­" Cloudflare
                    await page.mouse.move(random.randint(100, 600), random.randint(100, 600))
                    await page.mouse.wheel(0, random.randint(200, 500))
                    
                    # Äá»£i Cloudflare nháº£ trang (náº¿u tháº¥y mÃ n hÃ¬nh verify, Ã´ng hÃ£y click tay!)
                    await asyncio.sleep(random.uniform(5, 8)) 

                    # BÆ°á»›c 3: Kiá»ƒm tra ná»™i dung thá»±c sá»± Ä‘Ã£ load chÆ°a
                    title = (await page.title()).lower()
                    if "just a moment" in title or not title:
                        raise Exception("Blocked by Cloudflare")

                    domain = urlparse(url).netloc.lower()
                    content = (await page.content()).lower()

                    all_links = await page.query_selector_all('a')
                    ext_l = 0
                    for l in all_links:
                        try:
                            h = await l.get_attribute('href')
                            if h and 'http' in h and domain not in h: ext_l += 1
                        except: continue

                    dynamic_data = {
                        'Outlink_Ratio': ext_l / len(all_links) if len(all_links) > 0 else 0,
                        'HasExternalFormSubmit': 1 if await page.query_selector('form[action^="http"]') else 0,
                        'HasPasswordField': 1 if await page.query_selector('input[type="password"]') else 0,
                        'DomainTitleMatchScore': 1 if domain.split('.')[0] in title else 0,
                        'HasSocialNet': 1 if any(s in content for s in ['facebook', 'twitter', 'linkedin', 'instagram']) else 0,
                        'HasCopyrightInfo': 1 if ('Â©' in content or 'copyright' in content) else 0,
                        'HasDescription': 1 if await page.query_selector('meta[name="description"]') else 0,
                        'V9_Has_Hidden_IFrame': 1 if any(not await f.is_visible() for f in await page.query_selector_all('iframe')) else 0,
                        'V5_TLS_Issuer_Reputation': 1 if url.startswith('https') else 0,
                        'V4_DNS_Volatility_Count': 0
                    }
                    status = "SUCCESS"
                    await page.close()
                    break
                except Exception as e:
                    if not page.is_closed(): await page.close()
                    await asyncio.sleep(random.uniform(3, 5))

    log_handle.write(f"{url} | {status} | {datetime.now().strftime('%H:%M:%S')}\n")
    log_handle.flush()
    return {**static_data, **dynamic_data, 'label': label}

# =========================================================
# 5. CHÆ¯Æ NG TRÃŒNH CHÃNH (Báº¬T HEADLESS=FALSE)
# =========================================================
async def main():
    start_time = time.time()
    if not os.path.exists(INPUT_FILE): return
    df_all = pd.read_csv(INPUT_FILE)
    url_col = [c for c in df_all.columns if 'url' in c.lower()][0]
    label_col = [c for c in df_all.columns if 'label' in c.lower()][0]
    
    processed = set()
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, 'r') as f:
            for line in f: processed.add(line.split('|')[0].strip())
    
    df_to_do = df_all[~df_all[url_col].isin(processed)]
    total_todo = len(df_to_do)
    semaphore = asyncio.Semaphore(CONCURRENT_PAGES)

    async with async_playwright() as p:
        # CHÃš Ã: Äá»•i headless=False Ä‘á»ƒ Ã´ng cÃ³ thá»ƒ click xÃ¡c nháº­n khi cáº§n
        browser = await p.chromium.launch(headless=False, args=['--disable-blink-features=AutomationControlled'])
        
        # Giáº£ láº­p iPhone Ä‘á»ƒ vÆ°á»£t cÃ¡c bá»™ lá»c mÃ¡y tÃ­nh
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1",
            viewport={'width': 390, 'height': 844},
            has_touch=True
        )

        with open(LOG_FILE, 'a') as log_h:
            for i in range(0, total_todo, CONCURRENT_PAGES):
                batch = df_to_do.iloc[i : i + CONCURRENT_PAGES]
                tasks = [extract_task(row[url_col], row[label_col], context, semaphore, log_h) for _, row in batch.iterrows()]
                results = await asyncio.gather(*tasks)
                
                pd.DataFrame(results).to_csv(OUTPUT_FILE, mode='a', index=False, header=not os.path.exists(OUTPUT_FILE))
                
                done = i + len(batch)
                elapsed = time.time() - start_time
                speed = done / elapsed if elapsed > 0 else 0
                eta = str(timedelta(seconds=int((total_todo - done) / speed))) if speed > 0 else "N/A"
                print(f"ðŸš€ Xong: {done}/{total_todo} | Speed: {speed:.2f} u/s | ETA: {eta}")

        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())
