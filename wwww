import pandas as pd
import tldextract
import requests
import time
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ==================== C·∫§U H√åNH CHIA DATA ====================
INPUT_FILE = 'final_train_dataset_v9_4_fixed.csv'
# ƒê·∫∑t t√™n file output kh√°c nhau cho m√°y th·∫≠t v√† m√°y ·∫£o (vd: part1.csv v√† part2.csv)
OUTPUT_FILE = 'dataset_part_result.csv' 

# Chia ƒëo·∫°n: M√°y 1 (0 -> 23500), M√°y 2 (23501 -> 47000)
START_IDX = 23502  
END_IDX = 48685 

MAX_WORKERS = 5   # S·ªë lu·ªìng (Intel U5 d∆∞ s·ª©c ch·∫°y 5-8 lu·ªìng)
SAVE_INTERVAL = 50 # L∆∞u file sau m·ªói 50 d√≤ng ƒë·ªÉ tr√°nh m·∫•t data n·∫øu crash
# ============================================================

class RDAPScanner:
    def __init__(self):
        self.endpoints = [
            "https://rdap.verisign.com/com/v1/domain/",
            "https://rdap.org/domain/",
            "https://rdap.nic.cz/domain/"
        ]

    def get_age(self, url):
        try:
            ext = tldextract.extract(url)
            domain = f"{ext.domain}.{ext.suffix}".lower()
            if not ext.domain: return -1

            for base in self.endpoints:
                try:
                    # Timeout th·∫•p (5s) ƒë·ªÉ kh√¥ng b·ªã k·∫πt ·ªü link ch·∫øt
                    res = requests.get(base + domain, timeout=5)
                    if res.status_code == 200:
                        events = res.json().get('events', [])
                        for e in events:
                            if e.get('eventAction') in ['registration', 'created']:
                                dt = datetime.strptime(e.get('eventDate')[:10], '%Y-%m-%d')
                                return (datetime.now() - dt).days
                    elif res.status_code == 429: # B·ªã gi·ªõi h·∫°n l∆∞·ª£t truy c·∫≠p
                        time.sleep(5) 
                except: continue
            return -1
        except: return -1

def process_row(row_data):
    idx, url = row_data
    scanner = RDAPScanner()
    age = scanner.get_age(url)
    return idx, age

def main():
    # 1. ƒê·ªçc v√† c·∫Øt ƒëo·∫°n d·ªØ li·ªáu
    if not os.path.exists(INPUT_FILE):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {INPUT_FILE}"); return
        
    full_df = pd.read_csv(INPUT_FILE)
    df = full_df.iloc[START_IDX:END_IDX].copy()
    
    if 'domain_age' not in df.columns:
        df['domain_age'] = -1

    # L·ªçc nh·ªØng d√≤ng ch∆∞a qu√©t (ph√≤ng tr∆∞·ªùng h·ª£p √¥ng t·∫Øt ƒëi b·∫≠t l·∫°i)
    to_process = df[df['domain_age'] == -1]
    tasks = [(idx, row['url']) for idx, row in to_process.iterrows()]
    
    print(f"üöÄ [PART {START_IDX}-{END_IDX}] ƒêang qu√©t {len(tasks)} link b·∫±ng {MAX_WORKERS} lu·ªìng...")
    

    # 2. Ch·∫°y ƒëa lu·ªìng xuy√™n ƒë√™m
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_row, t): t for t in tasks}
        
        try:
            for i, future in enumerate(tqdm(as_completed(futures), total=len(futures))):
                idx, age = future.result()
                df.at[idx, 'domain_age'] = age
                
                # L∆∞u ƒë·ªãnh k·ª≥
                if i > 0 and i % SAVE_INTERVAL == 0:
                    df.to_csv(OUTPUT_FILE, index=False)
                
                # Gi√£n c√°ch nh·∫π ƒë·ªÉ b·∫£o v·ªá IP
                if i % MAX_WORKERS == 0:
                    time.sleep(1)
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è ƒêang d·ª´ng v√† l∆∞u d·ªØ li·ªáu...")
        finally:
            df.to_csv(OUTPUT_FILE, index=False)
            print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
